{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" src=\"../img/saturn.png\" width=\"300\" />\n",
    "\n",
    "# Machine Learning on Big Data with Dask\n",
    "\n",
    "## Single-node workflow\n",
    "\n",
    "We'll first start off with a typical data preparation and machine learning workflow utilizing only the Jupyter Server.\n",
    "\n",
    "\n",
    "## Monitor resource utilization\n",
    "\n",
    "For this workshop it's important to monitor CPU and memory utilization when running various commands. It will help with understanding which operations are slow - and which ones run faster on a cluster!\n",
    "\n",
    "To monitor resource utilization of the Jupyter Server, open a new Terminal window inside Jupyter Lab and run `htop`. You can position the window to view the notebook and terminal on the same screen:\n",
    "\n",
    "![htop](../img/htop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "This workshop will utilize [NYC taxi data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) for yellow taxi rides from the 2019 calendar year. The machine learning exercises involve predicting the \"tip fraction\" of each ride - how much a rider will tip the driver as a fraction of the charged fare amount.\n",
    "\n",
    "Let's operate with one month for now to explore the data and build out the machine learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 3.24 s, total: 15.6 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "taxi = pd.read_csv(\n",
    "    'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv',\n",
    "    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:59:47</td>\n",
       "      <td>2019-01-01 01:18:59</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 13:48:30</td>\n",
       "      <td>2018-12-21 13:52:40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:52:25</td>\n",
       "      <td>2018-11-28 15:55:45</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:56:57</td>\n",
       "      <td>2018-11-28 15:58:33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>55.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2019-01-01 00:46:40   2019-01-01 00:53:20                1   \n",
       "1         1  2019-01-01 00:59:47   2019-01-01 01:18:59                1   \n",
       "2         2  2018-12-21 13:48:30   2018-12-21 13:52:40                3   \n",
       "3         2  2018-11-28 15:52:25   2018-11-28 15:55:45                5   \n",
       "4         2  2018-11-28 15:56:57   2018-11-28 15:58:33                5   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.5           1                  N           151           239   \n",
       "1            2.6           1                  N           239           246   \n",
       "2            0.0           1                  N           236           236   \n",
       "3            0.0           1                  N           193           193   \n",
       "4            0.0           2                  N           193           193   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1          7.0    0.5      0.5        1.65           0.0   \n",
       "1             1         14.0    0.5      0.5        1.00           0.0   \n",
       "2             1          4.5    0.5      0.5        0.00           0.0   \n",
       "3             2          3.5    0.5      0.5        0.00           0.0   \n",
       "4             2         52.0    0.0      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3          9.95                   NaN  \n",
       "1                    0.3         16.30                   NaN  \n",
       "2                    0.3          5.80                   NaN  \n",
       "3                    0.3          7.55                   NaN  \n",
       "4                    0.3         55.55                   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "How many rows are in the `taxi` DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7667792"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory usage is also an important consideration, as DataFrames often take more space in memory than on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 1487.551776\n"
     ]
    }
   ],
   "source": [
    "taxi_bytes = taxi.memory_usage(deep=True).sum()\n",
    "print(f\"Size (MB): {taxi_bytes / 1e6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis\n",
    "\n",
    "For this workshop, we will just look at column statistics. There are many more explorary analyses that can performed with `pandas` and data visualization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.9 s, sys: 248 ms, total: 4.15 s\n",
      "Wall time: 4.15 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.637</td>\n",
       "      <td>0.540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_count</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.567</td>\n",
       "      <td>1.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>2.801</td>\n",
       "      <td>3.738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.80</td>\n",
       "      <td>831.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RatecodeID</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.058</td>\n",
       "      <td>0.678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PULocationID</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>165.501</td>\n",
       "      <td>66.392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.00</td>\n",
       "      <td>162.00</td>\n",
       "      <td>234.00</td>\n",
       "      <td>265.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOLocationID</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>163.753</td>\n",
       "      <td>70.364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.00</td>\n",
       "      <td>162.00</td>\n",
       "      <td>234.00</td>\n",
       "      <td>265.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.292</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>12.409</td>\n",
       "      <td>262.072</td>\n",
       "      <td>-362.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>13.50</td>\n",
       "      <td>623259.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.507</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>535.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mta_tax</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>60.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.827</td>\n",
       "      <td>2.501</td>\n",
       "      <td>-63.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.33</td>\n",
       "      <td>787.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>0.317</td>\n",
       "      <td>2.024</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3288.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_amount</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>15.682</td>\n",
       "      <td>262.293</td>\n",
       "      <td>-362.8</td>\n",
       "      <td>8.19</td>\n",
       "      <td>11.27</td>\n",
       "      <td>16.56</td>\n",
       "      <td>623261.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <td>2811814.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count     mean      std    min     25%     50%  \\\n",
       "VendorID               7667792.0    1.637    0.540    1.0    1.00    2.00   \n",
       "passenger_count        7667792.0    1.567    1.224    0.0    1.00    1.00   \n",
       "trip_distance          7667792.0    2.801    3.738    0.0    0.90    1.53   \n",
       "RatecodeID             7667792.0    1.058    0.678    1.0    1.00    1.00   \n",
       "PULocationID           7667792.0  165.501   66.392    1.0  130.00  162.00   \n",
       "DOLocationID           7667792.0  163.753   70.364    1.0  113.00  162.00   \n",
       "payment_type           7667792.0    1.292    0.473    1.0    1.00    1.00   \n",
       "fare_amount            7667792.0   12.409  262.072 -362.0    6.00    8.50   \n",
       "extra                  7667792.0    0.328    0.507  -60.0    0.00    0.00   \n",
       "mta_tax                7667792.0    0.497    0.053   -0.5    0.50    0.50   \n",
       "tip_amount             7667792.0    1.827    2.501  -63.5    0.00    1.43   \n",
       "tolls_amount           7667792.0    0.317    2.024  -70.0    0.00    0.00   \n",
       "improvement_surcharge  7667792.0    0.299    0.019   -0.3    0.30    0.30   \n",
       "total_amount           7667792.0   15.682  262.293 -362.8    8.19   11.27   \n",
       "congestion_surcharge   2811814.0    0.000    0.009    0.0    0.00    0.00   \n",
       "\n",
       "                          75%        max  \n",
       "VendorID                 2.00       4.00  \n",
       "passenger_count          2.00       9.00  \n",
       "trip_distance            2.80     831.80  \n",
       "RatecodeID               1.00      99.00  \n",
       "PULocationID           234.00     265.00  \n",
       "DOLocationID           234.00     265.00  \n",
       "payment_type             2.00       4.00  \n",
       "fare_amount             13.50  623259.86  \n",
       "extra                    0.50     535.38  \n",
       "mta_tax                  0.50      60.80  \n",
       "tip_amount               2.33     787.25  \n",
       "tolls_amount             0.00    3288.00  \n",
       "improvement_surcharge    0.30       0.60  \n",
       "total_amount            16.56  623261.66  \n",
       "congestion_surcharge     0.00       2.50  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.round(taxi.describe().T, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "We are using stateless features, meaning the features values for a given observation don't depend on other observations. This is allows us to create features before performing any data splitting.\n",
    "\n",
    "Then, split data into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify feature and label column names\n",
    "raw_features = [\n",
    "    'tpep_pickup_datetime', \n",
    "    'passenger_count', \n",
    "    'tip_amount', \n",
    "    'fare_amount',\n",
    "]\n",
    "features = [\n",
    "    'pickup_weekday', \n",
    "    'pickup_weekofyear', \n",
    "    'pickup_hour', \n",
    "    'pickup_week_hour', \n",
    "    'pickup_minute', \n",
    "    'passenger_count',\n",
    "]\n",
    "label = 'tip_fraction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(taxi_df):\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    '''\n",
    "    df = taxi_df[taxi_df.fare_amount > 0][raw_features].copy()  # avoid divide-by-zero\n",
    "    df[label] = df.tip_amount / df.fare_amount\n",
    "     \n",
    "    df['pickup_weekday'] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_weekofyear'] = df.tpep_pickup_datetime.dt.isocalendar().week\n",
    "    df['pickup_hour'] = df.tpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.tpep_pickup_datetime.dt.minute\n",
    "    df = df[features + [label]].astype(float).fillna(-1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_weekofyear</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_week_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>tip_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_weekday  pickup_weekofyear  pickup_hour  pickup_week_hour  \\\n",
       "0             1.0                1.0          0.0              24.0   \n",
       "1             1.0                1.0          0.0              24.0   \n",
       "2             4.0               51.0         13.0             109.0   \n",
       "3             2.0               48.0         15.0              63.0   \n",
       "4             2.0               48.0         15.0              63.0   \n",
       "\n",
       "   pickup_minute  passenger_count  tip_fraction  \n",
       "0           46.0              1.0      0.235714  \n",
       "1           59.0              1.0      0.071429  \n",
       "2           48.0              3.0      0.000000  \n",
       "3           52.0              5.0      0.000000  \n",
       "4           56.0              5.0      0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_feat = prep_df(taxi)\n",
    "taxi_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    taxi_feat[features], \n",
    "    taxi_feat[label], \n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5360764, 6), (5360764,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2297471, 6), (2297471,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "We'll train a linear model to predict `tip_fraction`. We define a `Pipeline` to encompass both feature scaling and model training. This will be useful later when performing a grid search.\n",
    "\n",
    "Evaluate the model against the test set using RMSE. We'll also save out the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', ElasticNet(normalize=False, max_iter=100, l1_ratio=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 235 ms, total: 15 s\n",
      "Wall time: 7.98 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/saturn/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 213133769.77430594, tolerance: 42626.7746654675\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fitted = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 162 ms, sys: 24.3 ms, total: 187 ms\n",
      "Wall time: 92.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = fitted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.118045186129104"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "with open('/tmp/model.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(fitted, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooray!\n",
    "\n",
    "We trained a terrible model. But that's okay. The point of this workshop is to scale our work, not make the model perfect!\n",
    "\n",
    "# Let's step things up\n",
    "\n",
    "We were able to train a model on a sample of the taxi data (single month from 2019). In many model building settings more data would be required. Follow below to see where the single-node environment starts to encounter challenges - the rest of the workshop will cover how Dask solves these problems!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process large dataset\n",
    "\n",
    "Let's look at the size of the files on disk using `s3fs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyc-tlc/trip data/yellow_tripdata_2019-01.csv, Size: 687.09 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-02.csv, Size: 649.88 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-03.csv, Size: 726.2 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-04.csv, Size: 689.21 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-05.csv, Size: 701.54 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-06.csv, Size: 643.49 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-07.csv, Size: 584.39 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-08.csv, Size: 562.39 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-09.csv, Size: 608.97 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-10.csv, Size: 669.17 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-11.csv, Size: 637.81 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-12.csv, Size: 639.11 MB\n",
      "\n",
      "Total size: 7.8 GB\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "files = s3.glob('s3://nyc-tlc/trip data/yellow_tripdata_2019-*.csv')\n",
    "total_size = 0\n",
    "for f in files:\n",
    "    size = s3.du(f)\n",
    "    total_size += size\n",
    "    \n",
    "    print(f\"{f}, Size: {round(size / 1e6, 2)} MB\")\n",
    "print()\n",
    "print(f\"Total size: {round(total_size / 1e9, 2)} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Files end up taking more space when loaded into memory, but let's see if this will fit on our Jupyter Server. We can loop through the files and concatenate them into one DataFrame. Watch memory utilization as the loop runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file):\n",
    "    df = pd.read_csv(\n",
    "        s3.open(file, mode='rb'),\n",
    "        parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    print(f)\n",
    "    df = load_csv(f)\n",
    "    print(f'{len(df)} rows, {df.memory_usage(deep=True).sum() / 1e6} MB')\n",
    "    dfs.append(df)\n",
    "taxi_big = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![explosion](https://media4.giphy.com/media/13d2jHlSlxklVe/giphy.gif)\n",
    "\n",
    "Oh no! Looks like we have enough memory to load the CSV files individually, but not to concatenate them together into one DataFrame.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with large dataset\n",
    "\n",
    "We are stuck here, because we need to be able to load the full dataset into memory to train with it.\n",
    "\n",
    "Think about all the data we're missing out on. All those observations, all those models that will never get a chance!\n",
    "\n",
    "<img src=\"https://media0.giphy.com/media/k61nOBRRBMxva/giphy.gif\" width=\"400\" alt=\"crying\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There must be a better way!\n",
    "\n",
    "<img src=\"https://docs.dask.org/en/latest/_images/dask_horizontal_no_pad.svg\" width=\"300\" alt=\"dask\" />\n",
    "\n",
    "With Dask, we can scale out to a cluster to address these problems. \n",
    "\n",
    "Move on to [03-dask-basics.ipynb](../03-dask-basics.ipynb) to get started!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
